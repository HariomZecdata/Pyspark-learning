FROM openjdk:11
LABEL maintainer="test"

# Spark Install
ARG SPARK_VERSION=3.3.2
ARG HADOOP_VERSION=3
ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$PATH"

RUN apt-get update && apt-get install -y curl python3 python3-pip && \
    curl -fsSL https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz | tar xz -C /opt && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} $SPARK_HOME && \
    pip3 install pyspark

WORKDIR /app
COPY broadcast_join.py /pyspark-learning/broadcast_join.py
CMD ["spark-class", "org.apache.spark.deploy.master.Master"]
